input {
  pipeline {
    address => VAR_PIPELINE_NAME
  }
}
filter {
    mutate {
        add_field => { "organization.name" => "cargill" }
        add_field => { "event.module" => "versa.sdwan" }
        add_field => { "event.dataset" => "versa.sdwan.os" }
        add_field => { "observer.vendor" => "versa" }
        add_field => { "observer.product" => "versa.sdwan.wan.os" }
        add_field => { "observer.type" => "versa.sdwan.os" }
    }
    ### Header
  ### Logstash tcp or udp in
  if [agent.type] == "logstash" {
    dissect {
      tag_on_failure => "_dateparsefailure_header"
      mapping => {
        message => "<%{pri}> %{rest_msg}"
      }
    }
  } else {
  ### Filebeats udp or tcp in
    dissect {
      tag_on_failure => "_dateparsefailure_header"
      mapping => {
        message => "%{?data} {%{?data}} <%{pri}> %{rest_msg}"
      }
    }
  }
  syslog_pri {
    syslog_pri_field_name => "pri"
  }
  mutate{
    remove_field => ["pri"]
  }
    # 1. Start by copying the original message to log.original.  We'll then pick the common fields and placing them under [tmp]. [tmp] is a temporary slot to work out the parsing

    mutate {
        add_field => {"[log.original]" => "%{[message]}"}
    }

    dissect {
        mapping => {
        "message" => "%{} %{[tmp][host]} %{[tmp][time]} %{[tmp][module]}, %{[tmp][rest_msg]}"
        }
    }

    # 2. Convert the timestamp and place that into [tmp][time]
    date {
        match => [ "[tmp][time]", "MMM dd yyyy HH:mm:ss",
              "MMM  d yyyy HH:mm:ss", "ISO8601" ]
    }

    # 3. Extract the host prodvided in the beggining of the message. Move it to log.source.hostname
    grok {
        match => { "[tmp][host]" => "{name=%{GREEDYDATA:log.source.hostname}}" }
    }

    # 4. Parse the SDWAN module that generated the logs
    mutate {
        add_field => { "[event.module]" => "%{[tmp][module]}"}
    }

    # 5. Take the rest of the SDWAN message, which is comprised of field=value split by comma. Throw in [tmp][rest_msg]
    kv {
        source => "[tmp][rest_msg]"
        field_split => "="
        field_split_pattern => ", "
        target => "tmp"
       # whitespace => "strict" #check later
    }

    # 6. We end up with all SDWAN specific fields from rest msg. Now use 3 mutate filters (for readability) to perform 3 actions below

        #a) Parse fields that belong to ECS into ECS fields
    mutate {
        rename => { "[tmp][alarmSeverity]" => "log.syslog.severity.name" }
        rename => { "[tmp][applianceName]" => "host.hostname"}
        rename => { "[tmp][alarmType]" => "event.action" }
        rename => { "[tmp][alarmCause]" => "event.dataset"} # check later
        rename => { "[tmp][alarmSeqNo]" => "error.id"}
        rename => { "[tmp][alarmEventType]" => "error.type"}
        rename => { "[tmp][alarmText]" => "error.message"}
        rename => { "[tmp][alarmClass]" => "rule.category"}
        rename => { "[tmp][serialNum]" => "host.id"}
        rename => { "[tmp][siteName]" => "network.name"}
        rename => { "[tmp][alarmKind]" => "event.reason"}
    }

        # b) Parse fields that don't belong to ECS into Labels (as per https://www.elastic.co/guide/en/ecs/current/ecs-custom-fields-in-ecs.html#_the_labels_field)
        # mutate {
        # rename => { "[tmp][alarmKey]" => "[labels][alarmKey]"}
        # }

        # c) Drop unused/unwanted fields
    mutate {
        remove_field => [ "[tmp]" ]
    }

    #7. Proceed to hardcoded evaluations

    # event kind (alert, event, metric, state, pipeline_error, signal)
    translate {
        field => "[event.module]"
        destination => "[event.kind]"
        dictionary => {
          "alarmLog" => "alert"
          "accessLog" => "state"
          "sfwAccessLog" => "state"
          "denyLog" => "state"
          "idpLog" => "alert"
          "avLog" => "alert"
          "ipfLog" => "alert"
          "urlfLog" => "alert"
          "dosThreatLog" => "alert"
          "flowIdLog" => "state"
          "flowMonLog" => "state"
          "flowMonHttpLog" => "state"
          "monStatsLog" => "metric"
          "bwMonLog" => "metric"
          "intfUtilLog" => "metric"
          "sdwanB2BSlamLog" => "metric"
          "tcpAppMonLog" => "metric"
        }
        fallback => "event"
    }

    # event category
    translate {
        field => "[error.type]"
        destination => "[event.category]"
        dictionary => {
          "equipmentAlarm" => "host"
        }
    }

    # event type
    translate {
        field => "[event.action]"
        destination => "[event.type]"
        dictionary => {
          "interface-down" => "error"
          "interface-up" => "info"
        }
    }

    # event outcome
    translate {
        field => "[event.dataset]"
        destination => "[event.outcome]"
        dictionary => {
          "outOfService" => "failure"
        }
    }

    # 8. Convert fields (i.e. extract site, appliance type, etc)
    if "" in [network.name] or ![network.name]  {
        mutate {
            add_field => {"[network.name]" => "%{[host.hostname]}" }
        }
    }

    mutate {
        add_field => {"[service.type]" => "%{[host.hostname]}"}
    }

    
    mutate {
        gsub => [
            "[service.type]", "(.*)-([a-z]*)", "\2",
            "[network.name]", "([a-z]*)([0-9].*)", "\1"
        ]
    }
    mutate{
      remove_field => ["rest_msg"]
    }
}
output {
  pipeline { send_to => [enrichments] }
}