# Copyright [2021] [Cargill, Incorporated.] 
# SPDX-License-Identifier: Apache-2.0
input {
  pipeline {
    address => VAR_PIPELINE_NAME
  }
}

filter {
  mutate {
      id => "cisco.dna-mutate-logsource"
      add_field => { "event.module" => "cisco.dna" }
      add_field => { "event.dataset" => "cisco.dna" }
      add_field => { "observer.vendor" => "cisco" }
      add_field => { "observer.product" => "cisco.dna" }
      add_field => { "observer.type" => "network_management" }
    }

  
# 1. Start by copying the original message to log.original.  We'll then pick the common fields and placing them under [tmp]. [tmp] is a temporary slot to work out the parsing

  mutate {
      id => "cisco.dna-mutate-logoriginal1"
      add_field => {"[log.original]" => "%{[message]}"}
  }

  mutate {
    id => "cisco.dna-mutate-logoriginal2"
    lowercase => ["[message]"]
  }



  # a. the block below will parse dna_event messages. luckly most of it is comprised of a json
  grok {
      id => "cisco.dna-grok-message"
      match => { "message" => "%{GREEDYDATA:[tmp][dna_event]}dnac_event\s-\s%{GREEDYDATA:[tmp][json]}" }
  }

  # b. parse syslog fields
  dissect {
  id => "cisco.dna-dissect-syslogfields"
    mapping => {
      "[tmp][dna_event]" => "%{[tmp][time]} {name=%{[tmp][observer]}} %{syslog_pri} %{log.syslog.priority} %{[tmp][intime]} %{[tmp][dna_process]} %{[tmp][origin]} -"
    }
  }

  syslog_pri {
      id => "cisco.dna-syslogpri"
  }

  mutate {
      id => "cisco.dna-mutate-splithostname"
      split => { "[tmp][observer]" => "."}
      add_field => { "observer.hostname" => "%{[tmp][observer][0]}"}
  }

  # b. parse dna center json
  # see logindexer-pipeline/issues/249 about whitespaces in the resulting fields
  json {
      id => "cisco.dna-json"
      source => "[tmp][json]"
      target => "[tmp]"
  }

    
  # c. pick dates from event
  date {
      id => "cisco.dna-date-created"
      match => [ "[tmp][timestamp]", "UNIX", "UNIX_MS" ]
      target => "event.created"
  }

  #there seems to be a bug in DNA center so don't be surprised with crazy start times like 142172-03-20T14:47:41.429Z
  date {
      id => "cisco.dna-date-start"
      match => ["[tmp][starttime]", "UNIX", "UNIX_MS"]
      target => "event.start"
  }

# 2. map DNA into ECS
    
  mutate {
      # cisco does not disclose their formats for DNA center (yet?). therefore we're not expecting a 100% error free on these translations
      # but in name of a more concise parser we'll avoid using the translate filter. id below will help to find for parsing errors
      id => "cisco.dna-mutate-map"
      rename => {"[tmp][type]" => "event.category"}
      rename => {"[tmp][subdomain]" => "host.type"}
      # rename => {"[tmp][source]" => "event.module"}
      rename => {"[tmp][note]" => "event.url"}
      rename => {"[tmp][ciscodnaeventlink]" => "event.reference"}
      rename => {"[tmp][domain]" => "event.provider"}
      rename => {"[tmp][eventid]" => "event.id"}
      rename => {"[tmp][details][assurance issue category]" => "error.type"}
      rename => {"[tmp][details][device]" => "host.hostname"}
      rename => {"[tmp][details][assurance issue details]" => "error.message"}
      rename => {"[tmp][detais][type]" => "host.type"}
      rename => {"[tmp][severity]" => "event.severity"} 
  }

  if "-" in [tmp][details][assurance issue name]
  {
    mutate {
      split => { "[tmp][details][assurance issue name]" => "-" }
      add_field => {"event.action" => "%{[tmp][details][assurance issue name][0]}"}
      add_field => {"event.reason" => "%{[tmp][details][assurance issue name][1]}"}

    }
  }
  else {
    mutate {
      copy => {"[tmp][details][assurance issue name]" => "event.reason"}
      copy => {"[tmp][details][assurance issue name]" => "event.action"}
      
    }
  }

  mutate {
    strip => ["event.action", "event.reason"]
  }
    
# 3. translate DNA into ECS

  translate {
          id => "cisco.dna-translate-category"
          field => "[tmp][details][assurance issue category]"
          dictionary => [
          "availability", "network" 
          ]
          exact => true
          # [field]-[error]
          fallback => "host"
          destination => "event.category"
      }
    
  translate {
          id => "cisco.dna-translate-kind"
          field => "[tmp][details][assurance issue status]"
          dictionary => [
          "resolved", "event",
          "active", "event"
          ]
          exact => true
          # [field]-[error]
          fallback => "event"
          destination => "event.kind"
      }

  translate {
      id => "cisco.dna-translate-type"
      field => "[tmp][category]"
      dictionary => [
        "warn", "info",
        "task_failure", "error",
        "error", "error"
      ]
      exact => true
      fallback => "info"
      destination => "event.type"
  }


# 4. Convert fields (i.e. extract site, appliance type, etc)

  if ![host.hostname] {
      mutate {
          id => "cisco.dna-mutate-addhost"
          add_field => {"host.hostname" => "%{observer.hostname}"}
      }
  }

  if "" in [network.name] or ![network.name]  {
      mutate {
          id => "cisco.dna-mutate-addnetwork"
          add_field => {"[network.name]" => "%{[host.hostname]}" }
      }
  }

  mutate {
      id => "cisco.dna-mutate-svctype"
      add_field => {"[service.type]" => "%{[host.hostname]}"}
  }


  mutate {
      id => "cisco.dna-mutate-gsubsvc"
      gsub => [
          "[service.type]", "(.*)-([a-z]*)", "\2",
          "[network.name]", "([a-z]*)([0-9].*)", "\1"
      ]
  }

# 5. Specific event/field extraction

  if "ssid" in [error.message] {
    grok {
      match => {
        "error.message" => [".*ssid\s%{GREEDYDATA:[network.name]}\.", ".*ssid\s%{GREEDYDATA:[network.name]}\s"]
      }
    }
  }

# 6. Drop fields

  mutate {
      id => "cisco.dna-drop"
      remove_field => ["[tmp]", "syslog_pri"]
  }


}


output {
  pipeline { send_to => [enrichments] }
}