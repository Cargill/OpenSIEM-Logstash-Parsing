# Copyright [2021] [Cargill, Incorporated.] 
# SPDX-License-Identifier: Apache-2.0
input {
  pipeline {
    address => VAR_PIPELINE_NAME
  }
}
filter {
  mutate {
    id => "cisco.dna-mutate-logsource"
    add_field => { "event.module" => "cisco.dna" }
    add_field => { "event.dataset" => "cisco.dna" }
    add_field => { "observer.vendor" => "cisco" }
    add_field => { "observer.product" => "cisco.dna" }
    add_field => { "observer.type" => "network_management" }
  }

  # 1. Start by copying the original message to log.original.  We'll then pick the common fields and placing them under [tmp]. [tmp] is a temporary slot to work out the parsing
  mutate {
    id => "cisco.dna-mutate-logoriginal1"
    add_field => {"[log.original]" => "%{[message]}"}
  }

  mutate {
    id => "cisco.dna-mutate-logoriginal2"
    lowercase => ["[message]"]
  }
  grok {
    tag_on_failure => "_parsefailure_header"
    match => { "message" => "(^(.*?)(<(?<pri>\d+)>)(\s)?(?<actual_msg>.*$))|(^(?<actual_msg>.*)$)" }
  }
  syslog_pri {
    id => "cisco.dna-syslogpri"
    syslog_pri_field_name => "pri" 
    remove_field => [ "pri" ]
  }

  # a. the block below will parse dna_event messages. luckly most of it is comprised of a json  
  if [actual_msg] =~ "dnac_event" {
    grok {
      id => "cisco.dna-grok-message1"
      match => { "actual_msg" => "%{GREEDYDATA:[tmp][dna_event]}dnac_event\s-\s%{GREEDYDATA:[tmp][json]}" }
    }
  }
  else {
    grok {
      id => "cisco.dna-grok-message2"
      match => { "actual_msg" => "%{GREEDYDATA:[tmp][dna_event]} - - %{GREEDYDATA:[tmp][json]}" }
    }
  }

  mutate {
    id => "cisco.dna-syslogrename"
    rename => {"[syslog_severity_code]" => "log.syslog.severity.code" }
    rename => {"[syslog_facility_code]" => "log.syslog.facility.code" }
    rename => {"[syslog_severity]" => "log.syslog.severity.name" }
    rename => {"[syslog_facility]" => "log.syslog.facility.name" }
  }

  mutate {
    id => "cisco.dna-mutate-splithostname1"
    add_field => {"host.hostname" => "%{log.source.hostname}"}
    add_field => {"host.domain" => "%{log.source.hostname}"}
    add_field => {"observer.hostname" => "%{log.source.hostname}"}
  }

  mutate {
    id => "cisco.dna-mutate-splithostname2"
    gsub => [
      "host.hostname", "([^.]+)\.(.*)", "\1",
      "observer.hostname", "([^.]+)\.(.*)", "\1",
      "host.domain", "([^.]+)\.(.*)", "\2"
    ]
  }

  # b. parse dna center json
  # see logindexer-pipeline/issues/249 about whitespaces in the resulting fields
  json {
    id => "cisco.dna-json"
    source => "[tmp][json]"
    target => "[tmp]"
  }
    
  # c. pick dates from event
  date {
    id => "cisco.dna-date-created"
    match => [ "[tmp][timestamp]", "UNIX", "UNIX_MS" ]
    target => "event.created"
  }

  #there seems to be a bug in DNA center so don't be surprised with crazy start times like 142172-03-20T14:47:41.429Z
  # date {
  #   id => "cisco.dna-date-start"
  #   match => ["[tmp][starttime]", "UNIX", "UNIX_MS"]
  #   target => "event.start"
  # }

  # 2. map DNA into ECS
  mutate {
    # cisco does not disclose their formats for DNA center (yet?). therefore we're not expecting a 100% error free on these translations
    # but in name of a more concise parser we'll avoid using the translate filter. id below will help to find for parsing errors
    id => "cisco.dna-mutate-map"
    rename => {"[tmp][type]" => "event.category"}
    rename => {"[tmp][subdomain]" => "host.type"}
    # rename => {"[tmp][source]" => "event.module"}
    rename => {"[tmp][note]" => "event.url"}
    rename => {"[tmp][ciscodnaeventlink]" => "event.reference"}
    rename => {"[tmp][domain]" => "event.provider"}
    rename => {"[tmp][eventid]" => "event.id"}
    rename => {"[tmp][details][assurance issue category]" => "error.type"}
    rename => {"[tmp][details][device]" => "host.hostname"}
    rename => {"[tmp][details][assurance issue details]" => "error.message"}
    rename => {"[tmp][detais][type]" => "host.type"}
    rename => {"[tmp][severity]" => "event.severity"} 
    rename => {"[tmp][details][assurance issue name]" => "event.reason"}
  }


    
  # 3. translate DNA into ECS
  translate {
    id => "cisco.dna-translate-category"
    field => "[tmp][details][assurance issue category]"
    dictionary => [
    "availability", "network", 
    "utilization", "network"
    ]
    exact => true
    # [field]-[error]
    fallback => "host"
    destination => "event.category"
  }
    
  translate {
    id => "cisco.dna-translate-kind"
    field => "[tmp][details][assurance issue status]"
    dictionary => [
    "resolved", "event",
    "active", "event"
    ]
    exact => true
    # [field]-[error]
    fallback => "event"
    destination => "event.kind"
  }

  translate {
    id => "cisco.dna-translate-type"
    field => "[tmp][category]"
    dictionary => [
      "warn", "info",
      "task_failure", "error",
      "error", "error"
    ]
    exact => true
    fallback => "info"
    destination => "event.type"
  }

  # 4. Specific event/field extraction
  if [event.reason] =~ ".*(increase|decrease).*on \w* in .*"
  {
    grok {
      match => {
        "[event.reason]" => ".*on %{WORD:[network.name]} in %{GREEDYDATA:geo.name}."
      }
    }
  }
  elseif "ssid" in [error.message] {
    grok {
      match => {
        "error.message" => [".*ssid\s%{GREEDYDATA:[network.name]}\.", ".*ssid\s%{GREEDYDATA:[network.name]}\s"]
      }
    }
  }

  # 5. Convert fields (i.e. extract site, appliance type, etc)
  if ![network.name] {
    mutate {
        id => "cisco.dna-mutate-addnetwork1"
        add_field => {"[network.name]" => "%{[host.hostname]}" }
    }
  }

  # 6. Drop fields
  mutate {
    id => "cisco.dna-drop"
    remove_field => [ "[tmp]", "actual_msg" ]
  }
}
output {
  pipeline { send_to => [enrichments] }
}