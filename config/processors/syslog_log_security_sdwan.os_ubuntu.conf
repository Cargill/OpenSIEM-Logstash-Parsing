# Copyright [2021] [Cargill, Incorporated.] 
# SPDX-License-Identifier: Apache-2.0
input {
  pipeline {
    address => VAR_PIPELINE_NAME
  }
}
<<<<<<< HEAD





filter {
  mutate {
    add_field => { "event.module" => "sdwan.os_ubuntu" }
    add_field => { "observer.vendor" => "versa" }
    add_field => { "observer.product" => "versa.sdwan.os_ubuntu" }
    add_field => { "observer.type" => "network_management" }
  }
    
  # 1. start by copying the original message to log.original.  we'll then pick the common fields and placing them under [tmp]. [tmp] is a temporary slot to work out the parsing

  mutate {
    id => "sdwan.os-mutate-logoriginal"
    tag_on_failure => "_mutate_error-sdwan.os-logoriginal"
    add_field => {"[log.original]" => "%{[message]}"}
    
  }
  mutate {
    lowercase => ["[message]"]
  }

  # 2. OS log format is not consistent. The easiest way to parse seem to be identifying the log type first and then using common parsing that work for that given process

  if "com.tailf.ncs.alarmman.common.alarm" in [message]
  {
    mutate {
      add_field => { "event.dataset" => "%{event.module}.alarmman"}
    }

    grok {
      tag_on_failure => "_grokparsefailure_header"
      match => { "message" => "%{GREEDYDATA:[tmp][header]} event %{GREEDYDATA:[tmp][msg]}.*\.alarm\[%{GREEDYDATA:[tmp][alarm_msg]}"}
    }


    # parse the header
    dissect {
      id => "sdwan.os-dissect-alarmman"
      tag_on_failure => "_dissect_error-sdwan.os-alarmman"
      mapping => {
        "[tmp][header]" => "%{} %{} <%{[syslog_pri]}>%{[tmp][date]} %{+[tmp][date]} %{+[tmp][date]} %{observer.hostname} %{}}"
      }
    }

    syslog_pri {}
    mutate {
      rename => { "syslog_severity_code" => "log.syslog.severity.code"}
      rename => { "syslog_severity" => "log.syslog.severity.name"}
      rename => { "syslog_facility" => "log.syslog.facility.name"}
      rename => { "syslog_facility_name" => "log.syslog.facility.code"}
    }

    # parse the log
    mutate {
      strip => ["[tmp][alarm_msg]", "[tmp][process]"]
    }
    kv {
      field_split => ","
      target => "[tmp][details]"
      source => "[tmp][alarm_msg]"
    }

    # depending on the alarm/object, the field [tmp][details][device] will present either the appliance name or if the alarm comes straight from director, the value "vdirector". 
    # in the first case we need to inform the director is the observer
    # in the second case we need to inform the director is the host

    if [tmp][details][device] == "vdirector"
    {
      mutate {
        update => { "[tmp][details][device]" => "%{observer.hostname}"} #director is the host
      }
    }
   

    mutate {
      rename => { "[tmp][details][device]" => "host.hostname"}
      rename => { "[tmp][details][alarm-text]" => "error.message"}
      split => { "[tmp][details][type]" => ":"}
      add_field => { "error.type" => "%{[tmp][details][type][1]}"}
    }

    # if the alarm comes with a severity code, we'll trust that instead of that taken from syslog_pri, as versa strangely sends different severity on syslog_pri and inside the payload 
    if [tmp][details][severity] {
    mutate {
      remove_field => ["log.syslog.severity.name", "log.syslog.severity.code"]
    }
    }

    # rfc 5424 translation. see https://datatracker.ietf.org/doc/html/rfc5424#appendix-a.3 on why we do this
    translate {
      field => "[tmp][details][severity]"
      destination => "log.syslog.severity.name"
      dictionary => {
        "warning" => "warning"
        "indeterminate" => "informational"
        "minor" => "notice"
        "major" => "error"
        "critical" => "critical"
        "cleared" => "informational"
      }
      fallback => "debug"
    }

    translate {
      field => "[tmp][details][severity]"
      destination => "log.syslog.severity.code"
      dictionary => {
        "warning" => 4
        "indeterminate" => 6
        "minor" => 5
        "major" => 3
        "critical" => 2
        "cleared" => 6
      }
      fallback => 7
    }

   mutate {
     remove_field => ["[tmp]", "syslog_pri"]
   }
  
  }

  #this is a more generic parse but don't expect it to work on all kinds of messages
  else {
    dissect {
        id => "sdwan.os-dissect"
        tag_on_failure => "_dissect_error-sdwan.os-message"
        mapping => {
        "message" => "%{} %{[tmp][host]} %{[tmp][rest_msg]}"
        }
  }
  
  }

}

=======
filter {
    mutate {
        add_field => { "event.module" => "sdwan.os.ubuntu" }
        add_field => { "observer.vendor" => "versa" }
        add_field => { "observer.product" => "versa.sdwan.wan.os" }
        add_field => { "observer.type" => "versa.sdwan.os" }
    }
    ### Header
  ### Logstash tcp or udp in
  if [agent.type] == "logstash" {
    dissect {
      tag_on_failure => "_dateparsefailure_header"
      mapping => {
        message => "<%{pri}> %{rest_msg}"
      }
    }
  } else {
  ### Filebeats udp or tcp in
    dissect {
      tag_on_failure => "_dateparsefailure_header"
      mapping => {
        message => "%{?data} {%{?data}} <%{pri}> %{rest_msg}"
      }
    }
  }
  syslog_pri {
    syslog_pri_field_name => "pri"
  }
  mutate{
    remove_field => ["pri"]
  }
        # 1. Start by copying the original message to log.original.  We'll then pick the common fields and placing them under [tmp]. [tmp] is a temporary slot to work out the parsing

    mutate {
        add_field => {"[log.original]" => "%{[message]}"}
    }

    dissect {
        mapping => {
        "message" => "%{} %{[tmp][host]} %{[tmp][time]} %{[tmp][module]}, %{[tmp][rest_msg]}"
        }
    }

    # 2. Convert the timestamp and place that into [tmp][time]
    date {
        match => [ "[tmp][time]", "MMM dd yyyy HH:mm:ss",
              "MMM  d yyyy HH:mm:ss", "ISO8601" ]
    }

    # 3. Extract the host prodvided in the beggining of the message. Move it to log.source.hostname
    grok {
        match => { "[tmp][host]" => "{name=%{GREEDYDATA:log.source.hostname}}" }
    }

    # 4. Parse the SDWAN module that generated the logs
    mutate {
        add_field => { "[event_kind]" => "%{[tmp][module]}"}
    }

    # 5. Take the rest of the SDWAN message, which is comprised of field=value split by comma. Throw in [tmp][rest_msg]
    kv {
        source => "[tmp][rest_msg]"
        field_split => "="
        field_split_pattern => ", "
        target => "tmp"
       # whitespace => "strict" #check later
    }

    # 6. We end up with all SDWAN specific fields from rest msg. Now use 3 mutate filters (for readability) to perform 3 actions below

        #a) Parse fields that belong to ECS into ECS fields
    mutate {
        rename => { "[tmp][alarmSeverity]" => "log.syslog.severity.name" }
        rename => { "[tmp][applianceName]" => "host.hostname"}
        rename => { "[tmp][alarmType]" => "event.action" }
        rename => { "[tmp][alarmCause]" => "event.dataset"} # check later
        rename => { "[tmp][alarmSeqNo]" => "error.id"}
        rename => { "[tmp][alarmEventType]" => "error.type"}
        rename => { "[tmp][alarmText]" => "error.message"}
        rename => { "[tmp][alarmClass]" => "rule.category"}
        rename => { "[tmp][serialNum]" => "host.id"}
        rename => { "[tmp][siteName]" => "network.name"}
        rename => { "[tmp][alarmKind]" => "event.reason"}
    }

        # b) Parse fields that don't belong to ECS into Labels (as per https://www.elastic.co/guide/en/ecs/current/ecs-custom-fields-in-ecs.html#_the_labels_field)
        # mutate {
        # rename => { "[tmp][alarmKey]" => "[labels][alarmKey]"}
        # }

        # c) Drop unused/unwanted fields
    mutate {
        remove_field => [ "[tmp]" ]
    }

    #7. Proceed to hardcoded evaluations

    # event kind (alert, event, metric, state, pipeline_error, signal)
    translate {
        field => "[event_kind]"
        destination => "[event.kind]"
        dictionary => {
          "alarmLog" => "alert"
          "accessLog" => "state"
          "sfwAccessLog" => "state"
          "denyLog" => "state"
          "idpLog" => "alert"
          "avLog" => "alert"
          "ipfLog" => "alert"
          "urlfLog" => "alert"
          "dosThreatLog" => "alert"
          "flowIdLog" => "state"
          "flowMonLog" => "state"
          "flowMonHttpLog" => "state"
          "monStatsLog" => "metric"
          "bwMonLog" => "metric"
          "intfUtilLog" => "metric"
          "sdwanB2BSlamLog" => "metric"
          "tcpAppMonLog" => "metric"
        }
        fallback => "event"
    }

    # event category
    translate {
        field => "[error.type]"
        destination => "[event.category]"
        dictionary => {
          "equipmentAlarm" => "host"
        }
    }

    # event type
    translate {
        field => "[event.action]"
        destination => "[event.type]"
        dictionary => {
          "interface-down" => "error"
          "interface-up" => "info"
        }
    }

    # event outcome
    translate {
        field => "[event.dataset]"
        destination => "[event.outcome]"
        dictionary => {
          "outOfService" => "failure"
        }
    }

    # 8. Convert fields (i.e. extract site, appliance type, etc)
    if "" in [network.name] or ![network.name]  {
        mutate {
            add_field => {"[network.name]" => "%{[host.hostname]}" }
        }
    }

    mutate {
        add_field => {"[service.type]" => "%{[host.hostname]}"}
    }

    
    mutate {
        gsub => [
            "[service.type]", "(.*)-([a-z]*)", "\2",
            "[network.name]", "([a-z]*)([0-9].*)", "\1"
        ]
    }
    mutate{
      remove_field => ["rest_msg"]
    }

}
>>>>>>> upstream/master
output {
  pipeline { send_to => [enrichments] }
}
