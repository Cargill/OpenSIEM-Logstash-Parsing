# Copyright [2021] [Cargill, Incorporated.] 
# SPDX-License-Identifier: Apache-2.0
input {
  pipeline {
    address => VAR_PIPELINE_NAME
  }
}

filter {
  mutate {
    add_field => { "[event][module]" => "riverbed.netim" }
    add_field => { "[observer][vendor]" => "riverbed" }
    add_field => { "[observer][product]" => "riverbed.netim" }
    add_field => { "[observer][type]" => "nms" }
  }
    
  # 1. start by copying the original message to [log][original].  we'll then pick the common fields and placing them under [tmp]. [tmp] is a temporary slot to work out the parsing

  mutate {
    id => "riverbed.netim-mutate-logoriginal"
    tag_on_failure => "_mutate_error-riverbed.netim-logoriginal"
    add_field => {"[log][original]" => "%{[message]}"}
    lowercase => ["[message]"]
  }

  # dissect header
  dissect {
    id => "riverbed.netim-dissect"
    tag_on_failure => "_dissect_error-riverbed.netim-message"
    mapping => {
      "message" => "%{} %{} <%{syslog_pri}>%{} - %{[[tmp][dissect]]}: %{[[tmp][rest_msg]]}"
    }
  }

  mutate {
    strip => ["[tmp][dissect]"]
  }


  # if msg contains sample details, we'll copy it to sample_raw
  if [tmp][rest_msg] =~ "complete sample"
  {
    grok {
      id => "riverbed.netim-grok"
      tag_on_failure => "_grokparsefailure_sample"
      match => { "[tmp][rest_msg]" => "%{GREEDYDATA:[[tmp][details]]}complete sample:%{GREEDYDATA:[[tmp][sample_raw]]}"}
      timeout_millis => 500
    }
  }

  # parse and rename syslog fields
  syslog_pri {}
  mutate {
    rename => { "syslog_severity_code" => "[log][syslog][severity][code]"}
    rename => { "syslog_severity" => "[log][syslog][severity][name]"}
    rename => { "syslog_facility" => "[log][syslog][facility][name]"}
    rename => { "syslog_facility_name" => "[log][syslog][facility][name]"}
    rename => { "syslog_facility_code" => "[log][syslog][facility][code]"}
  }

  # extract severity. the severity send in the via syslog is not always the same as the severity sent inside the alarm
  grok {
    tag_on_failure => "_grokparsefailure_severity"
    match => { "[tmp][dissect]" => "%{GREEDYDATA} %{NOTSPACE:[[tmp][app_severity]]} severity"}            
    timeout_millis => 500
  }

  # if we found a severity field, we'll extract it and apply rfc 5424 translation. see https://datatracker.ietf.org/doc/html/rfc5424#appendix-a.3 on why we do this
  if [tmp][app_severity] {
    mutate {
      remove_field => ["[log][syslog][severity][code]", "[log][syslog][severity][name]"]
    }
    
    translate {
      source => "[tmp][app_severity]"
      target => "[log][syslog][severity][code]"
      dictionary => {
        "critical" => 2
        "major" => 3
        "minor" => 4
        "normal" => 5
      }
      fallback => 7
    }

    translate {
      source => "[log][syslog][severity][code]"
      target => "[log][syslog][severity][name]"
      dictionary => {
        "0" => "emergency"
        "1" => "alert" 
        "2" => "critical" 
        "3" => "error" 
        "4" => "warning" 
        "5" => "notice" 
        "6" => "informational"
        "7" => "debug"
      }
      fallback => "informational"
    }
  }

  # next mutate and KVs extract details from the alarm
  mutate {
    gsub => [ "[tmp][details]", "\n", ",",
              "[tmp][sample_raw]", "\n", ",",
              "[tmp][sample_raw]", "\t", ""
    ]
  }
  mutate {
    gsub => [ "[tmp][details]", "^,", "",
              "[tmp][sample_raw]", "^,", ""
    ]
    gsub => [ "[tmp][details]", ",$", "",
              "[tmp][sample_raw]", ",$", ""
    ]
  }

  kv {
    id => "riverbed.netim-kv-restmsg"
    tag_on_failure => "_kv_error-riverbed.netim-restmsg"
    source => "[tmp][details]"
    field_split => ","
    value_split => ":"
    target => "[tmp][details]"
    recursive => false
  }

  kv {
    tag_on_failure => "_kv_error-riverbed.netim-sample"
    source => "[tmp][sample_raw]"
    field_split => ","
    value_split => ":"
    target => "[tmp][sample_raw]"
    recursive => false
    
  }

  # [tmp][sample_raw] contains dynamic fields (depending on the alarm), and the field names contain spaces. to remove spaces we'll
  # convert it to a json then use gsub and convert it back. those fields will be mapped into labels
  json_encode {
    source => "[tmp][sample_raw]"
    target => "[tmp][sample_json]"
  }

  mutate {
    gsub => [ "[tmp][sample_json]", " ", "_"
    ]
  }

  json {
    source => "[tmp][sample_json]"
    target => "[labels]"
  }

  # rename netim fields to ECS
  mutate {
    rename => { "[tmp][details][primaryaddress]" => "[host][ip]"}
    rename => { "[tmp][details][sysname]" => "[host][hostname]"}
    rename => { "[tmp][details][alert description]" => "[rule][category]"}
    rename => { "[tmp][details][alert name]" => "[rule][ruleset]"}
    rename => { "[tmp][details][metric class]" => "[event][reason]"}
    rename => { "[tmp][details][metric]" => "[event][action]"}
    add_field => {"[event][category]" => "network"}
    add_field => {"[event][kind]" => "alert"}
    add_field => {"[event][outcome]" => "failure"}
    rename => { "[tmp][details][ifalias]" => "[observer][ingress][interface][alias]"}
    rename => { "[tmp][details][ifIndex]" => "[observer][ingress][interface][id]"}
    rename => { "[tmp][details][preferredname]" => "[observer][ingress][interface][name]"}
  }

  # we'll know build the error message so it's clear in a single line what the issue is
  mutate {
  add_field => {"[error][message]" => "%{[[tmp][details][display name]]} (%{[[tmp][details][ifdescr]]}) %{[[event][action]]} %{[[tmp][details][threshold]]}"}
  }

  # the actual time the alarm started is provided by "crossed at". we'll parse it to [event][start] but will remove the timezone first
  mutate {
    gsub => ["[tmp][details][crossed at]", "cdt ", ""]
  }

  date {
    match => ["[tmp][details][crossed at]", "EEE MMM dd HH:mm:ss yyyy"]
    target => "[event][start]"
    timezone => "CST6CDT"
  }

  # remove unecessary fields
  mutate {
    remove_field => ["[tmp]", "syslog_pri" ]
  }
 

}
output {
  pipeline { send_to => [enrichments] }
}
